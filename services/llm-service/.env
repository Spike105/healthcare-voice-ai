# LLM Service (.env)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=tinyllama:latest